{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maaz202/Artificial-Intelligence/blob/main/Self_Driving_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nml4_eVPm3jO",
        "outputId": "cfb314c1-82d5-41df-c95f-09c3792c5767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.2\n",
            "Collecting python-constraint\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python-constraint\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24058 sha256=57b96d083163799ae9674bb3e80f03f0fd3879d469df42d501075aa7bd5b065e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/f2/2b/cb08b5fe129e4f69b7033061f256e5c551b0aa1160c2872aee\n",
            "Successfully built python-constraint\n",
            "Installing collected packages: python-constraint\n",
            "Successfully installed python-constraint-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn\n",
        "!pip install python-constraint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from constraint import *\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import heapq\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import seaborn as sns\n",
        "from hmmlearn import hmm\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "        self.children = []\n",
        "        self.value = 0  # Minimax value\n",
        "\n",
        "class SelfDrivingCarEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Environment for the AI-based self-driving car simulation.\n",
        "    Follows the gym interface.\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, grid_size=(5, 5), start_state=(0, 0), goal_state=(4, 4), num_goals=1):\n",
        "        super(SelfDrivingCarEnv, self).__init__()\n",
        "\n",
        "        self.action_space = spaces.Discrete(4)  # Up, down, left, right\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(np.prod(grid_size),), dtype=np.uint8)\n",
        "\n",
        "        self.grid_size = grid_size\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "        self.num_goals = num_goals\n",
        "        self.agent_position = start_state\n",
        "\n",
        "        self.grid = self._create_grid()\n",
        "        self.state_feature_matrix = self._create_state_feature_matrix()\n",
        "        self.bayesian_model = self._create_bayesian_model()\n",
        "        self.hmm_model = self._create_hmm_model()\n",
        "        self.linear_regression_model = self._create_linear_regression_model()\n",
        "\n",
        "    def _create_grid(self):\n",
        "        grid = np.zeros(self.grid_size)\n",
        "        # Add goals, barriers, etc.\n",
        "        grid[self.goal_state] = 2  # Goal\n",
        "        grid[1, 2] = 1  # Barrier\n",
        "        return grid\n",
        "\n",
        "    def _create_state_feature_matrix(self):\n",
        "        # Generate a feature matrix for each state\n",
        "        feature_matrix = np.zeros((self.grid_size[0] * self.grid_size[1], 4))\n",
        "        for i in range(self.grid_size[0]):\n",
        "            for j in range(self.grid_size[1]):\n",
        "                feature_matrix[i * self.grid_size[1] + j] = [i, j, self.grid[i, j] == 1, self.grid[i, j] == 2]\n",
        "        return feature_matrix\n",
        "\n",
        "    def _create_bayesian_model(self):\n",
        "        # Create a Bayesian model for predicting the next state\n",
        "        model = GaussianNB()\n",
        "        return model\n",
        "\n",
        "    def _create_hmm_model(self):\n",
        "        # Create an HMM model for predicting the next state\n",
        "        states = [\"Up\", \"Down\", \"Left\", \"Right\"]\n",
        "        model = hmm.CategoricalHMM(n_components=len(states))\n",
        "        model.startprob_ = np.array([0.25, 0.25, 0.25, 0.25])  # Equal initial probability for each state\n",
        "        model.transmat_ = np.array([[0.7, 0.1, 0.1, 0.1],\n",
        "                                   [0.1, 0.7, 0.1, 0.1],\n",
        "                                   [0.1, 0.1, 0.7, 0.1],\n",
        "                                   [0.1, 0.1, 0.1, 0.7]])  # Transition probabilities\n",
        "        model.emissionprob_ = np.array([[0.9, 0.1, 0, 0],\n",
        "                                       [0, 0.9, 0.1, 0],\n",
        "                                       [0, 0, 0.9, 0.1],\n",
        "                                       [0.1, 0, 0, 0.9]])  # Emission probabilities\n",
        "        return model\n",
        "\n",
        "    def _create_linear_regression_model(self):\n",
        "        # Create a Linear Regression model for predicting the next state\n",
        "        model = LinearRegression()\n",
        "        return model\n",
        "\n",
        "    def step(self, action):\n",
        "        # Update agent position based on action\n",
        "        if action == 0:  # Up\n",
        "            self.agent_position = (self.agent_position[0], max(self.agent_position[1] - 1, 0))\n",
        "        elif action == 1:  # Down\n",
        "            self.agent_position = (self.agent_position[0], min(self.agent_position[1] + 1, self.grid_size[1] - 1))\n",
        "        elif action == 2:  # Left\n",
        "            self.agent_position = (max(self.agent_position[0] - 1, 0), self.agent_position[1])\n",
        "        elif action == 3:  # Right\n",
        "            self.agent_position = (min(self.agent_position[0] + 1, self.grid_size[0] - 1), self.agent_position[1])\n",
        "\n",
        "        # Check for goals, barriers, etc.\n",
        "        reward = 0\n",
        "        done = False\n",
        "        if self.agent_position == self.goal_state:\n",
        "            reward = 100\n",
        "            done = True\n",
        "        elif self.grid[self.agent_position[0], self.agent_position[1]] == 1:  # Barrier\n",
        "            reward = -10\n",
        "            done = True\n",
        "\n",
        "        # Update the Bayesian model\n",
        "        state_feature = self.state_feature_matrix[self.agent_position[0] * self.grid_size[1] + self.agent_position[1]]\n",
        "        self.bayesian_model.partial_fit([state_feature], [action])\n",
        "\n",
        "        # Update the HMM model\n",
        "        self.hmm_model.fit([action])\n",
        "\n",
        "        # Update the Linear Regression model\n",
        "        self.linear_regression_model.partial_fit([state_feature], [action])\n",
        "\n",
        "        return self.grid.flatten(), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_position = self.start_state\n",
        "        self.grid = self._create_grid()\n",
        "        return self.grid.flatten()\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        # Render the grid and the agent\n",
        "        if close:\n",
        "            return\n",
        "        print(self.grid)\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "    # Helper function to get the next state given the current state and action\n",
        "        next_state = None\n",
        "        if action == 0:  # Up\n",
        "            next_state = (state[0], max(state[1] - 1, 0))\n",
        "        elif action == 1:  # Down\n",
        "            next_state = (state[0], min(state[1] + 1, self.grid_size[1] - 1))\n",
        "        elif action == 2:  # Left\n",
        "            next_state = (max(state[0] - 1, 0), state[1])\n",
        "        elif action == 3:  # Right\n",
        "            next_state = (min(state[0] + 1, self.grid_size[0] - 1), state[1])\n",
        "\n",
        "        if next_state is None or (next_state[0] < 0 or next_state[0] >= self.grid_size[0] or next_state[1] < 0 or next_state[1] >= self.grid_size[1]) or self.grid[next_state[0], next_state[1]] == 1:  # Check if the new state is out of bounds or a barrier\n",
        "            return None\n",
        "        else:\n",
        "            return next_state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bfs_search(environment):\n",
        "    start = environment.start_state\n",
        "    frontier = deque([(start, [start])])\n",
        "    explored = set()\n",
        "\n",
        "    while frontier:\n",
        "        current, path = frontier.popleft()\n",
        "        if current == environment.goal_state:\n",
        "            return path\n",
        "        if current not in explored:\n",
        "            explored.add(current)\n",
        "            for action in range(environment.action_space.n):\n",
        "                new_state = environment.get_next_state(current, action)\n",
        "                if new_state is not None and new_state not in explored:\n",
        "                    frontier.append((new_state, path + [new_state]))\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def dfs_search(environment):\n",
        "    start = environment.start_state\n",
        "    frontier = [(start, [start])]\n",
        "    explored = set()\n",
        "\n",
        "    while frontier:\n",
        "        current, path = frontier.pop()\n",
        "        if current == environment.goal_state:\n",
        "            return path\n",
        "        if current not in explored:\n",
        "            explored.add(current)\n",
        "            for action in range(environment.action_space.n):\n",
        "                new_state = environment.get_next_state(current, action)\n",
        "                if new_state is not None and new_state not in explored:\n",
        "                    frontier.append((new_state, path + [new_state]))\n",
        "    return None\n",
        "\n",
        "\n",
        "def heuristic(state, goal):\n",
        "    # Euclidean distance heuristic\n",
        "    if state is None:\n",
        "        return float('inf')\n",
        "    else:\n",
        "        return ((state[0] - goal[0]) ** 2 + (state[1] - goal[1]) ** 2) ** 0.5\n",
        "\n",
        "\n",
        "def a_star_search(environment):\n",
        "    start = environment.start_state\n",
        "    frontier = [(0, start, [start])]\n",
        "    explored = set()\n",
        "\n",
        "    while frontier:\n",
        "        _, current, path = heapq.heappop(frontier)\n",
        "        if current == environment.goal_state:\n",
        "            return path\n",
        "        if current not in explored:\n",
        "            explored.add(current)\n",
        "            for action in range(environment.action_space.n):\n",
        "                new_state = environment.get_next_state(current, action)\n",
        "                if new_state is not None:\n",
        "                    new_cost = len(path) + 1\n",
        "                    new_priority = new_cost + heuristic(new_state, environment.goal_state)\n",
        "                    heapq.heappush(frontier, (new_priority, new_state, path + [new_state]))\n",
        "    return None\n",
        "\n",
        "\n",
        "def csp_solver(environment):\n",
        "    problem = Problem()\n",
        "\n",
        "    # Add variables (agent position)\n",
        "    problem.addVariable(\"x\", list(range(environment.grid_size[0])))\n",
        "    problem.addVariable(\"y\", list(range(environment.grid_size[1])))\n",
        "\n",
        "    # Add constraints\n",
        "    def is_valid_position(x, y):\n",
        "        return environment.grid[x, y] != 1  # Check for barriers\n",
        "\n",
        "    problem.addConstraint(is_valid_position, [\"x\", \"y\"])\n",
        "\n",
        "    # Solve the problem\n",
        "    solutions = problem.getSolutions()\n",
        "\n",
        "    if solutions:\n",
        "        # Reconstruct the path from the first solution\n",
        "        solution = solutions[0]\n",
        "        path = [(solution[\"x\"], solution[\"y\"])]\n",
        "        current_state = (solution[\"x\"], solution[\"y\"])\n",
        "\n",
        "        while current_state != environment.goal_state:\n",
        "            for action in range(environment.action_space.n):\n",
        "                new_state = environment.get_next_state(current_state, action)\n",
        "                if new_state is not None and new_state not in path:\n",
        "                    current_state = new_state\n",
        "                    path.append(current_state)\n",
        "                    break\n",
        "\n",
        "        return path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def hill_climbing_search(environment):\n",
        "    start = environment.start_state\n",
        "    current_state = start\n",
        "    path = [start]\n",
        "\n",
        "    while current_state != environment.goal_state:\n",
        "        # Check all possible actions from the current state\n",
        "        best_action = None\n",
        "        best_state = current_state\n",
        "        best_cost = float('inf')\n",
        "\n",
        "        for action in range(environment.action_space.n):\n",
        "            new_state = environment.get_next_state(current_state, action)\n",
        "            if new_state is not None and environment.grid[new_state[0], new_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "                new_cost = heuristic(new_state, environment.goal_state)\n",
        "                if new_cost < best_cost:\n",
        "                    best_action = action\n",
        "                    best_state = new_state\n",
        "                    best_cost = new_cost\n",
        "\n",
        "        if best_action is None:\n",
        "            # No better state found, return the current path\n",
        "            return path\n",
        "\n",
        "        current_state = best_state\n",
        "        path.append(current_state)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "def local_beam_search(environment, beam_width=3):\n",
        "    start = environment.start_state\n",
        "    frontier = [(start, [start], heuristic(start, environment.goal_state))]\n",
        "    explored = set()\n",
        "\n",
        "    while frontier:\n",
        "        # Select the beam_width best states from the frontier\n",
        "        frontier.sort(key=lambda x: x[2])\n",
        "        states = [state[0] for state in frontier[:beam_width]]\n",
        "        paths = [state[1] for state in frontier[:beam_width]]\n",
        "        frontier = frontier[beam_width:]\n",
        "\n",
        "        # Expand the selected states\n",
        "        new_frontier = []\n",
        "        for state, path in zip(states, paths):\n",
        "            if state == environment.goal_state:\n",
        "                return path\n",
        "            if state not in explored:\n",
        "                explored.add(state)\n",
        "                for action in range(environment.action_space.n):\n",
        "                    new_state = environment.get_next_state(state, action)\n",
        "                    if new_state is not None and environment.grid[new_state[0], new_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "                        new_path = path + [new_state]\n",
        "                        new_priority = heuristic(new_state, environment.goal_state)\n",
        "                        new_frontier.append((new_state, new_path, new_priority))\n",
        "\n",
        "        frontier.extend(new_frontier)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def alpha_beta_pruning(environment, max_depth=3):\n",
        "    def min_value(node, alpha, beta, depth):\n",
        "        if depth == 0 or environment.agent_position == environment.goal_state:\n",
        "            return heuristic(node.state, environment.goal_state)\n",
        "\n",
        "        node.value = math.inf\n",
        "        for action in range(environment.action_space.n):\n",
        "            new_state = environment.get_next_state(node.state, action)\n",
        "            if environment.grid[new_state[0], new_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "                child = Node(new_state)\n",
        "                node.children.append(child)\n",
        "                node.value = min(node.value, max_value(child, alpha, beta, depth - 1))\n",
        "                if node.value <= alpha:\n",
        "                    return node.value\n",
        "                beta = min(beta, node.value)\n",
        "        return node.value\n",
        "\n",
        "    def max_value(node, alpha, beta, depth):\n",
        "        if depth == 0 or environment.agent_position == environment.goal_state:\n",
        "            return heuristic(node.state, environment.goal_state)\n",
        "\n",
        "        node.value = -math.inf\n",
        "        for action in range(environment.action_space.n):\n",
        "            new_state = environment.get_next_state(node.state, action)\n",
        "            if environment.grid[new_state[0], new_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "                child = Node(new_state)\n",
        "                node.children.append(child)\n",
        "                node.value = max(node.value, min_value(child, alpha, beta, depth - 1))\n",
        "                if node.value >= beta:\n",
        "                    return node.value\n",
        "                alpha = max(alpha, node.value)\n",
        "        return node.value\n",
        "\n",
        "    start = Node(environment.start_state)\n",
        "    alpha_beta_pruning_result = max_value(start, -math.inf, math.inf, max_depth)\n",
        "\n",
        "    # Reconstruct the path\n",
        "    path = [start.state]\n",
        "    current = start\n",
        "    while current.state != environment.goal_state:\n",
        "        if current.children:\n",
        "            best_child = max(current.children, key=lambda child: child.value)\n",
        "            path.append(best_child.state)\n",
        "            current = best_child\n",
        "        else:\n",
        "            break  # No more children, exit the loop\n",
        "\n",
        "    return path\n",
        "\n",
        "def bayesian_search(environment):\n",
        "    # Fit the Bayesian model\n",
        "    X = environment.state_feature_matrix\n",
        "    y = np.zeros(X.shape[0], dtype=int)  # Dummy labels, we don't need them for prediction\n",
        "    environment.bayesian_model.fit(X, y)\n",
        "\n",
        "    start = environment.start_state\n",
        "    path = [start]\n",
        "    current_state = start\n",
        "\n",
        "    while current_state != environment.goal_state:\n",
        "        # Use the Bayesian model to predict the next action\n",
        "        state_feature = environment.state_feature_matrix[current_state[0] * environment.grid_size[1] + current_state[1]]\n",
        "        predicted_action = environment.bayesian_model.predict([state_feature])[0]\n",
        "\n",
        "        # Get the next state based on the predicted action\n",
        "        next_state = environment.get_next_state(current_state, predicted_action)\n",
        "\n",
        "        if environment.grid[next_state[0], next_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "            current_state = next_state\n",
        "            path.append(current_state)\n",
        "        else:\n",
        "            # If the predicted action leads to a barrier, choose a random action\n",
        "            action = np.random.randint(0, environment.action_space.n)\n",
        "            next_state = environment.get_next_state(current_state, action)\n",
        "            if environment.grid[next_state[0], next_state[1]] != 1:\n",
        "                current_state = next_state\n",
        "                path.append(current_state)\n",
        "\n",
        "    return path\n",
        "\n",
        "def hmm_search(environment):\n",
        "    start = environment.start_state\n",
        "    path = [start]\n",
        "    current_state = start\n",
        "\n",
        "    while current_state != environment.goal_state:\n",
        "        # Use the HMM model to predict the next action\n",
        "        predicted_action = environment.hmm_model.predict([environment.agent_position])[0]\n",
        "\n",
        "        # Get the next state based on the predicted action\n",
        "        next_state = environment.get_next_state(current_state, predicted_action)\n",
        "\n",
        "        if environment.grid[next_state[0], next_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "            current_state = next_state\n",
        "            path.append(current_state)\n",
        "        else:\n",
        "            # If the predicted action leads to a barrier, choose a random action\n",
        "            action = np.random.randint(0, environment.action_space.n)\n",
        "            next_state = environment.get_next_state(current_state, action)\n",
        "            if environment.grid[next_state[0], next_state[1]] != 1:\n",
        "                current_state = next_state\n",
        "                path.append(current_state)\n",
        "\n",
        "    return path\n",
        "\n",
        "def _create_linear_regression_model(self):\n",
        "    # Create a Linear Regression model for predicting the next state\n",
        "    model = LinearRegression()\n",
        "    return model\n",
        "\n",
        "def linear_regression_search(environment):\n",
        "    start = environment.start_state\n",
        "    path = [start]\n",
        "    current_state = start\n",
        "\n",
        "    # Train the Linear Regression model\n",
        "    X = environment.state_feature_matrix\n",
        "    y = np.array([environment.action_space.n for _ in range(X.shape[0])]).reshape(-1, 1)\n",
        "    environment.linear_regression_model.fit(X, y)\n",
        "\n",
        "    while current_state != environment.goal_state:\n",
        "        # Use the Linear Regression model to predict the next action\n",
        "        state_feature = environment.state_feature_matrix[current_state[0] * environment.grid_size[1] + current_state[1]]\n",
        "        predicted_action = environment.linear_regression_model.predict([state_feature])[0]\n",
        "\n",
        "        # Get the next state based on the predicted action\n",
        "        next_state = environment.get_next_state(current_state, int(predicted_action))\n",
        "\n",
        "        if next_state is not None and environment.grid[next_state[0], next_state[1]] != 1:  # Check if the new state is not a barrier\n",
        "            current_state = next_state\n",
        "            path.append(current_state)\n",
        "        else:\n",
        "            # If the predicted action leads to a barrier, choose a random action\n",
        "            action = np.random.randint(0, environment.action_space.n)\n",
        "            next_state = environment.get_next_state(current_state, action)\n",
        "            if next_state is not None and environment.grid[next_state[0], next_state[1]] != 1:\n",
        "                current_state = next_state\n",
        "                path.append(current_state)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def render_solution(environment, solution):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(environment.grid, cmap='gray')\n",
        "\n",
        "    # Plot the agent's path\n",
        "    if solution:\n",
        "        if isinstance(solution, list):\n",
        "            x, y = zip(*solution)\n",
        "            plt.plot(x, y, 'r-', linewidth=2)\n",
        "        elif isinstance(solution, tuple):\n",
        "            plt.plot([solution[0]], [solution[1]], 'r-', linewidth=2)\n",
        "        else:\n",
        "            print(\"Unsupported solution format.\")\n",
        "    else:\n",
        "        print(\"No solution found.\")\n",
        "\n",
        "    # Plot the start and goal positions\n",
        "    plt.plot(environment.start_state[0], environment.start_state[1], 'go', markersize=10)\n",
        "    plt.plot(environment.goal_state[0], environment.goal_state[1], 'ro', markersize=10)\n",
        "\n",
        "    plt.title('Self-Driving Car Environment')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = SelfDrivingCarEnv()\n",
        "\n",
        "    algorithm = input(\"Select the algorithm (BFS, DFS, A*, CSP, Hill Climbing, Local Beam Search, Alpha-Beta Pruning, Bayesian Search, HMM Search, Linear Regression Search): \").lower()\n",
        "\n",
        "    if algorithm == 'bfs':\n",
        "        solution = bfs_search(env)\n",
        "    elif algorithm == 'dfs':\n",
        "        solution = dfs_search(env)\n",
        "    elif algorithm == 'a*':\n",
        "        solution = a_star_search(env)\n",
        "    elif algorithm == 'csp':\n",
        "        solution = csp_solver(env)\n",
        "        if solution:\n",
        "            print(\"Solution found:\", solution)\n",
        "        else:\n",
        "            print(\"No solution found.\")\n",
        "        return\n",
        "    elif algorithm == 'hill climbing':\n",
        "        solution = hill_climbing_search(env)\n",
        "    elif algorithm == 'local beam search':\n",
        "        beam_width = int(input(\"Enter the beam width: \"))\n",
        "        solution = local_beam_search(env, beam_width)\n",
        "    elif algorithm == 'alpha-beta pruning':\n",
        "        max_depth = int(input(\"Enter the maximum depth: \"))\n",
        "        solution = alpha_beta_pruning(env, max_depth)\n",
        "    elif algorithm == 'bayesian search':\n",
        "        solution = bayesian_search(env)\n",
        "    elif algorithm == 'hmm search':\n",
        "        solution = hmm_search(env)\n",
        "    elif algorithm == 'linear regression search':\n",
        "        solution = linear_regression_search(env)\n",
        "    else:\n",
        "        print(\"Invalid algorithm selected.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    if solution:\n",
        "        print(\"Solution found:\", solution)\n",
        "        render_solution(env, solution)\n",
        "    else:\n",
        "        print(\"No solution found.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "q64g8i2OnDWW",
        "outputId": "480325f4-f717-4b25-a570-726bbf42580c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select the algorithm (BFS, DFS, A*, CSP, Hill Climbing, Local Beam Search, Alpha-Beta Pruning, Bayesian Search, HMM Search, Linear Regression Search): BFS\n",
            "Solution found: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 4), (2, 4), (3, 4), (4, 4)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqIAAAK9CAYAAAD/gQ69AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAya0lEQVR4nO3de5hVdb348c9mgJnhmqDoQVC8lqDoScnwriCoiaGZlHUEtLIU0sj6RReBczQ85knLW+QlzskQ1MR6yhuZYKYmghLS0cTQMBXUFBQYUGb9/piY4wjCQAwfhv16Pc88tNesvfdn5juT71l77b1LRVEUAQAAW1iL7AEAAChPQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUiGHDhkWPHj0abHvrrbfic5/7XOy0005RKpXi/PPP3yKzTJw4MUqlUjz33HMbfd0ePXrEsGHDNvtMbNjYsWOjVCpljwE0M0IUmqG5c+fGqaeeGrvuumtUVVXFzjvvHMcee2xceeWVm+0+vvvd78bEiRPjS1/6Uvz0pz+Nf/u3f1vnfs8991yUSqX6j1atWsX2228fhxxySHzzm9+Mv/71r5ttpq1dTU1NXH755XHwwQdHx44do6qqKvbee+8YMWJE/PnPf27y+58+fXqDtXjvx+TJk5t8Bv7PNddcExMnTsweA7ZqJe81D83LQw89FEcffXTssssuMXTo0Nhpp51i4cKF8cgjj8Szzz4b8+fP3+jbHDZsWEyfPr3BUciPfvSj0bJly3jwwQfXe93nnnsudtttt/j0pz8dJ5xwQtTW1sbrr78eM2fOjNtvvz1KpVLccMMN8alPfapRs6xevTrefvvtqKys3OgjbCtXrowWLVpEq1atNup6m8Orr74axx13XMyaNStOPPHE6N+/f7Rr1y6efvrpmDx5crz88suxatWqJp1h+vTpcfTRR8eXv/zl6NOnz1qfP/zww2PXXXdtkvt+55134p133omqqqomuf3maN99943tt98+pk+fnj0KbLVaZg8AbJyLL744OnbsGDNnzowPfOADDT63ePHizXY/ixcvjp49ezZ6/w9/+MPx2c9+tsG2559/PgYMGBBDhw6NffbZJ/bff//3vf6yZcuibdu2UVFRERUVFZs0c2Vl5SZdb3MYNmxYPP7443HbbbfFJz7xiQaf+4//+I/41re+tVnuZ833aX0OP/zwOPXUUzfL/TVWy5Yto2XL9f8npba2NlatWiVWgXoemodm5tlnn41evXqtFaEREV26dFlr20033RQHHnhgVFdXR6dOneJTn/pULFy48H1vf83DuwsWLIhf//rX9Q/rbso5m7vuumtMnDgxVq1aFZdeemn99jXngc6YMSPOOeec6NKlS3Tr1q3B59bc34knnhi77777Om+/b9++cdBBB9Vffu85omtu6/e//32MGjUqdthhh2jbtm2cfPLJ8corrzS4rdra2hg7dmx07do12rRpE0cffXT86U9/atR5p3/4wx/i17/+dZx11llrRWhEXSBfdtll9Zf/+Mc/xrBhw2L33XePqqqq2GmnneLMM8+M1157rcH11px3+ac//SlOP/302G677eKwww5b7yyNVSqVYsSIEXHHHXfEvvvuG5WVldGrV6+4++676/e57bbb6tfpvSZMmBClUimefPLJBrOu6z5+9rOfRa9evaKysrL+9h9//PE4/vjjo0OHDtGuXbvo169fPPLIIw2uvzHr16NHjzjxxBNj+vTpcdBBB0V1dXXst99+9Ucjb7/99thvv/2iqqoqDjzwwHj88cfX+pqeeuqpOPXUU6NTp05RVVUVBx10UPzyl7/cpJl69OgR8+bNixkzZtT/Dh111FEbWBUoP46IQjOz6667xsMPPxxPPvlk7Lvvvuvd9+KLL47vfOc7cdppp8XnPve5eOWVV+LKK6+MI444Ih5//PF1xuw+++wTP/3pT+MrX/lKdOvWLb761a9GRMQOO+ywSfP27ds39thjj5g2bdpanzvnnHNihx12iAsvvDCWLVu2zusPGTIkzjjjjJg5c2aDh5uff/75eOSRR+J73/veBmcYOXJkbLfddjFmzJh47rnn4oorrogRI0bElClT6vcZPXp0XHrppTFo0KAYOHBgzJkzJwYOHBg1NTUbvP01sfJ+59G+17Rp0+Ivf/lLDB8+PHbaaaeYN29e/PjHP4558+bFI488slbQffKTn4y99torvvvd70ZjzqZ6880349VXX11re+fOnRvc9oMPPhi33357nHPOOdG+ffv44Q9/GJ/4xCfir3/9a3Tu3Dk+9rGPRbt27eKWW26JI488ssFtTZkyJXr16rXBn8Hf/va3ccstt8SIESNi++23rw+0ww8/PDp06BBf//rXo1WrVjFhwoQ46qijYsaMGXHwwQc3uI3GrF9ExPz58+P000+Ps88+Oz772c/GZZddFoMGDYof/ehH8c1vfjPOOeeciIgYP358nHbaafH0009HixZ1x2PmzZsXhx56aOy8887xjW98I9q2bRu33HJLDB48OH7+85/HySefvFEzXXHFFTFy5Mho165d/dHwHXfccb3fKyhLBdCs3HvvvUVFRUVRUVFR9O3bt/j6179e3HPPPcWqVasa7Pfcc88VFRUVxcUXX9xg+9y5c4uWLVs22D506NBi1113bbDfrrvuWnzsYx/b4DwLFiwoIqL43ve+9777fPzjHy8ioliyZElRFEXxk5/8pIiI4rDDDiveeeedBvuu+dyCBQuKoiiKJUuWFJWVlcVXv/rVBvtdeumlRalUKp5//vkGMw8dOnSt2+rfv39RW1tbv/0rX/lKUVFRUbzxxhtFURTFyy+/XLRs2bIYPHhwg/sYO3ZsERENbnNdTj755CIiitdff329+62xfPnytbbdfPPNRUQUDzzwQP22MWPGFBFRfPrTn27U7d5///1FRLzvx0svvVS/b0QUrVu3LubPn1+/bc6cOUVEFFdeeWX9tk9/+tNFly5dGqzTSy+9VLRo0aL493//97VmfbeIKFq0aFHMmzevwfbBgwcXrVu3Lp599tn6bS+++GLRvn374ogjjqjf1tj1K4q6tY+I4qGHHqrfds899xQRUVRXVzf4OZkwYUIREcX9999fv61fv37FfvvtV9TU1NRvq62tLQ455JBir7322qSZevXqVRx55JEF8P48NA/NzLHHHhsPP/xwnHTSSTFnzpy49NJLY+DAgbHzzjs3eBjx9ttvj9ra2jjttNPi1Vdfrf/YaaedYq+99or7779/i83crl27iKg7Uvdun//85zd4PmiHDh3i+OOPj1tuuaXB0cApU6bERz/60dhll102eP9f+MIXGhwJPPzww2P16tXx/PPPR0TEfffdF++88079EbM1Ro4cucHbjohYunRpRES0b9++UftXV1fX/++ampp49dVX46Mf/WhERMyePXut/b/4xS826nbXuPDCC2PatGlrfXTq1KnBfv3794899tij/nLv3r2jQ4cO8Ze//KV+25AhQ2Lx4sUNnnBz2223RW1tbQwZMmSDsxx55JENzjVevXp13HvvvTF48OAGp1z8y7/8S5x++unx4IMP1n8/19jQ+q3Rs2fP6Nu3b/3lNUdWjznmmAY/J2u2r/k6//73v8dvf/vbOO200+qPJr/66qvx2muvxcCBA+OZZ56Jv/3tb5s0E7B+HpqHZqhPnz5x++23x6pVq2LOnDkxderUuPzyy+PUU0+NJ554Inr27BnPPPNMFEURe+211zpvY2OfWf7KK6/E6tWr6y+3a9euPjA35K233oqItUNtt912a9T1hwwZEnfccUc8/PDDccghh8Szzz4bs2bNiiuuuKJR139vrG633XYREfH6669HRNTHw5577tlgv06dOtXvuz4dOnSIiLrQXtfpDu/197//PcaNGxeTJ09e6wlmS5YsWWv/xn6f1thvv/2if//+G9xvXRG/3Xbb1X9fIiKOO+646NixY0yZMiX69esXEXV/BBxwwAGx9957b/A+3jv7K6+8EsuXL48PfvCDa+27zz77RG1tbSxcuDB69er1vnO+d/3eb7+OHTtGRET37t3XuX3N9efPnx9FUcR3vvOd+M53vrPOr2Px4sWx8847b/RMwPoJUWjGWrduHX369Ik+ffrE3nvvHcOHD49bb701xowZE7W1tVEqleKuu+5a51HHxkbkGn369GlwtGfMmDExduzYRl33ySefjC5dutQH2xrvPjK4PoMGDYo2bdrELbfcEoccckjccsst0aJFi/jkJz/ZqOu/31HXYjO9et2HPvShiKh7fdfDDz98g/ufdtpp8dBDD8XXvva1OOCAA6Jdu3ZRW1sbxx13XNTW1q61f2O/TxurMd+XysrKGDx4cEydOjWuueaaWLRoUfz+97+P7373u426j80xe2PX7/3229D113zPL7jgghg4cOA6933vHylN/TMF5UKIwjZizbPHX3rppYiI2GOPPaIoithtt90adeRqQ372s5/FihUr6i+/3zPZ3+vhhx+OZ599dq2XdtoYbdu2jRNPPDFuvfXW+P73vx9TpkyJww8/PLp27brJt/lua15bc/78+Q2O4L322muNOsI1aNCgGD9+fNx0000bDNHXX3897rvvvhg3blxceOGF9dufeeaZTZy+6Q0ZMiT++7//O+6777743//93yiKolEPy6/LDjvsEG3atImnn356rc899dRT0aJFi7WOYDa1NT/LrVq1atSR5MbyTlOwYc4RhWbm/vvvX+dRlzvvvDMiov4hz1NOOSUqKipi3Lhxa+1fFMVaLxW0IYceemj079+//qMxIfr888/HsGHDonXr1vG1r31to+7vvYYMGRIvvvhiXH/99TFnzpxNDqF16devX7Rs2TKuvfbaBtuvuuqqRl2/b9++cdxxx8X1118fd9xxx1qfX7VqVVxwwQUR8X9H0t67Jo09zSBD//79o1OnTjFlypSYMmVKfOQjH9no0wXWqKioiAEDBsQvfvGLBi8JtmjRopg0aVIcdthhax05b2pdunSJo446KiZMmFD/h9y7vfelohqrbdu28cYbb/yT08G2zRFRaGZGjhwZy5cvj5NPPjk+9KEPxapVq+Khhx6KKVOmRI8ePWL48OERUXdE9KKLLorRo0fHc889F4MHD4727dvHggULYurUqfGFL3yhPo42h9mzZ8dNN90UtbW18cYbb8TMmTPj5z//eZRKpfjpT38avXv3/qdu/4QTToj27dvHBRdcEBUVFet8vc5NteOOO8Z5550X//Vf/xUnnXRSHHfccTFnzpy46667Yvvtt2/Uka3/+Z//iQEDBsQpp5wSgwYNin79+kXbtm3jmWeeicmTJ8dLL70Ul112WXTo0CGOOOKIuPTSS+Ptt9+OnXfeOe69995YsGDBZvt6fve7363zZad69+69SevQqlWrOOWUU2Ly5MmxbNmyBq+JuikuuuiimDZtWhx22GFxzjnnRMuWLWPChAmxcuXKBq83uyVdffXVcdhhh8V+++0Xn//852P33XePRYsWxcMPPxwvvPBCzJkzZ6Nv88ADD4xrr702Lrroothzzz2jS5cuccwxxzTB9NB8CVFoZi677LK49dZb484774wf//jHsWrVqthll13inHPOiW9/+9sNnizzjW98I/bee++4/PLLY9y4cRFR98SNAQMGxEknnbRZ57r55pvj5ptvjpYtW0aHDh1ir732ivPPPz+++MUvNuqZ7RtSVVUVJ510UvzsZz+L/v37r/PF+/8Z//mf/xlt2rSJ6667Ln7zm99E37594957743DDjusUe8EtMMOO8RDDz0U11xzTUyZMiW+9a1vxapVq2LXXXeNk046Kc4777z6fSdNmhQjR46Mq6++OoqiiAEDBsRdd9212U41+OEPf7jO7WPGjNnkPwiGDBkS119/fZRKpTjttNP+mfGiV69e8bvf/S5Gjx4d48ePj9ra2jj44IPjpptuWus1RLeUnj17xmOPPRbjxo2LiRMnxmuvvRZdunSJf/3Xf21wCsXGuPDCC+P555+PSy+9NN5888048sgjhSi8h/eaB3gfb7zxRmy33XZx0UUXbba36ATg/zhHFCCiwROx1lhz3qa3ZgRoGh6aB4i618acOHFinHDCCdGuXbt48MEH4+abb44BAwbEoYcemj0ewDZJiAJE3RN5WrZsGZdeemksXbq0/glMF110UfZoANss54gCAJDCOaIAAKQQogAApGjW54jW1tbGiy++GO3bt/dWagAAW4GiKOLNN9+Mrl27RosW6z/m2axD9MUXX9zi70kMAMCGLVy4MLp167befZr1Q/Pt27fPHiFFVVVVTJo0qVHv9kLzZq3Lh7UuH9a6vJTzejem05p1iJbrw/GlUinatGlTtl9/ObHW5cNalw9rXV7Keb0b8zU36xAFAKD5EqIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQos1QUV3EopWLoqguskcBANhkLbMHoJGqImL/iDg4oqZTTZz9v2dHfDki/h4Rf4iIORFRkzkgAMDGEaLNwR4RMSQiWkXEew+CfiAijouIfhExJSKe3aKTAQBsMg/Nb+32iIjPRN2fDKVYe8Va/GN7y3/st8cWnQ4AYJNtFSF69dVXR48ePaKqqioOPvjgePTRR7NH2jpURd2R0IgNr9Sazw/5x/UAALZy6SE6ZcqUGDVqVIwZMyZmz54d+++/fwwcODAWL16cPVq+/aPu4fjGrlKLf+y/f5NNBACw2aSH6Pe///34/Oc/H8OHD4+ePXvGj370o2jTpk3ceOON2aPlO3gTrlNs4vUAALaw1CcrrVq1KmbNmhWjR4+u39aiRYvo379/PPzww2vtv3Llyli5cmX95aVLl0ZERFVVVZRKpaYfeAsqqouo6bQJT4NvERGdIqq2q4pSzbb1PSlH1dXVDf5l22Wty4e1Li/luN5FUURNTeMaplQURdqLUb744oux8847x0MPPRR9+/at3/71r389ZsyYEX/4wx8a7D927NgYN27cWrczadKkaNOmTZPPuyUtWrmo7iWaNtGEfSbEjpU7bsaJAAA2bPny5XH66afHkiVLokOHDuvdt1m9fNPo0aNj1KhR9ZeXLl0a3bt3jzPPPHObPCIaX97065/3xfMcEd0GVFdXx4033hhnnnlmrFixInscmpC1Lh/WuryU43pvzDHO1BDdfvvto6KiIhYtWtRg+6JFi2KnnXZaa//KysqorKxca3tjD/82Kyui7sXqPxAbdyZvbUS8EVHz+jb4PSljK1asKJv/Ayt31rp8WOvyYr3XLfXJSq1bt44DDzww7rvvvvpttbW1cd999zV4qL5s/SHqXiN0Y5T+cT0AgK1c+kPzo0aNiqFDh8ZBBx0UH/nIR+KKK66IZcuWxfDhw7NHyzcn6t4xqWU07k+G2oh45x/XAwDYyqWH6JAhQ+KVV16JCy+8MF5++eU44IAD4u67744dd/REm6iJurft/EzUReb6YrT2H/9OCe85DwA0C+khGhExYsSIGDFiRPYYW6dnI+Jn0fC95t8dpLVR93D8O+G95gGAZmWrCFE24NmI+H7UvWPSwRHR6V2feyPqzgl9IiJWvveKAABbLyHaXNREXXD+IWJudUS7yoi3Vkbs5wl4AEAzJUSboe1WROy8IuJv2YMAAPwT0t9rHgCA8iREAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASNEyewCA9xo7dmz2CFtcixZ1xwVGjx4dtbW1ydNsWeW43kAdR0QBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIkRqiDzzwQAwaNCi6du0apVIp7rjjjsxxAADYglJDdNmyZbH//vvH1VdfnTkGAAAJWmbe+fHHHx/HH3985ggAACRJDdGNtXLlyli5cmX95aVLl0ZERFVVVZRKpayxtrhSTU1EUUSpVIrqqqrscWhC1dXVDf4tFy1alN/p62u+5nL82svt57tcf6/LVTmud1EUUVNT06h9S0VRFE08T6OUSqWYOnVqDB48+H33GTt2bIwbN26t7ZMmTYo2bdo04XRblwFnnRXVr70WKzp3jntvuCF7HACAesuXL4/TTz89lixZEh06dFjvvs0qRNd1RLR79+5ld0R0fk1NdC2KeLFUij0dEd2mVVdXx4033hhnnnlmrFixInucLWb06NHZI2xxLVq0iH333TeefPLJqK2tzR5nixo/fnz2CFtUuf5el6tyXO81R0QbE6LN6qH5ysrKqKysXGt7Yw//bivW/OVQFEXZ/FCXuxUrVpTVWpdbiL1bbW1t2X395fSz/W7l9ntd7qz3upXfyUgAAGwVUo+IvvXWWzF//vz6ywsWLIgnnngiOnXqFLvsskviZAAANLXUEH3sscfi6KOPrr88atSoiIgYOnRoTJw4MWkqAAC2hNQQPeqoo2Irea4UAABbmHNEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASNEyewCA9xo7dmz2CFtcdXV13HzzzTF+/PhYsWJF9jgAW4QjogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKRodIi++OKLm/3Ox48fH3369In27dtHly5dYvDgwfH0009v9vsBAGDr0+gQ7dWrV0yaNGmz3vmMGTPi3HPPjUceeSSmTZsWb7/9dgwYMCCWLVu2We8HAICtT8vG7njxxRfH2WefHVOnTo0JEyZEp06d/uk7v/vuuxtcnjhxYnTp0iVmzZoVRxxxxD99+wAAbL0aHaLnnHNOHH/88XHWWWdFz54947rrrotBgwZt1mGWLFkSEfG+kbty5cpYuXJl/eWlS5dGRERVVVWUSqXNOsvWrFRTE1EUUSqVorqqKnscmlB1dXWDf9l2WevyYa3LSzmud1EUUVNT06h9S0VRFBt7B1dddVV85StfiX322SdatmzYsrNnz97Ym4uIiNra2jjppJPijTfeiAcffHCd+4wdOzbGjRu31vZJkyZFmzZtNul+m6MBZ50V1a+9Fis6d457b7ghexwAgHrLly+P008/PZYsWRIdOnRY774bHaLPP/98DB8+PJ588sk4++yz1wrRMWPGbPzEEfGlL30p7rrrrnjwwQejW7du69xnXUdEu3fvXnZHROfX1ETXoogXS6XY0xHRbVp1dXXceOONceaZZ8aKFSuyx6EJWevyYa3LSzmu95ojoo0J0UY/NB8Rcd1118VXv/rV6N+/f8ybNy922GGHf2rQNUaMGBG/+tWv4oEHHnjfCI2IqKysjMrKyrW2N/bw77ZizV8ORVGUzQ91uVuxYoW1LhPWunxY6/Jivdet0SF63HHHxaOPPhpXXXVVnHHGGZvlzouiiJEjR8bUqVNj+vTpsdtuu22W2wUAYOvX6BBdvXp1/PGPf1zvEcuNde6558akSZPiF7/4RbRv3z5efvnliIjo2LFjWZ3UCwBQjhodotOmTdvsd37ttddGRMRRRx3VYPtPfvKTGDZs2Ga/PwAAth4bdY7o5rYJT9gHAGAb4b3mAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIIUQBAEghRAEASCFEAQBIkRqi1157bfTu3Ts6dOgQHTp0iL59+8Zdd92VORIAAFtIaoh269YtLrnkkpg1a1Y89thjccwxx8THP/7xmDdvXuZYAABsAS0z73zQoEENLl988cVx7bXXxiOPPBK9evVKmgoAgC0hNUTfbfXq1XHrrbfGsmXLom/fvuvcZ+XKlbFy5cr6y0uXLo2IiKqqqiiVSltkzq1BqaYmoiiiVCpFdVVV9jg0oerq6gb/su2y1uXDWpeXclzvoiiipqamUfuWiqIomnie9Zo7d2707ds3ampqol27djFp0qQ44YQT1rnv2LFjY9y4cWttnzRpUrRp06apR91qDDjrrKh+7bVY0blz3HvDDdnjAADUW758eZx++umxZMmS6NChw3r3TQ/RVatWxV//+tdYsmRJ3HbbbXH99dfHjBkzomfPnmvtu64jot27dy+7I6Lza2qia1HEi6VS7OmI6Daturo6brzxxjjzzDNjxYoV2ePQhKx1+bDW5aUc13vNEdHGhGj6Q/OtW7eOPffcMyIiDjzwwJg5c2b84Ac/iAkTJqy1b2VlZVRWVq61vbGHf7cVa/5yKIqibH6oy92KFSusdZmw1uXDWpcX671uW93riNbW1jY46gkAwLYp9Yjo6NGj4/jjj49ddtkl3nzzzZg0aVJMnz497rnnnsyxAADYAlJDdPHixXHGGWfESy+9FB07dozevXvHPffcE8cee2zmWAAAbAGpIXqDZ3wDAJStre4cUQAAyoMQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIIUQBQAghRAFACCFEAUAIEXL7AEAgPJQFEX2CFvc22+/HXfeeWcsWbIkWrVqlT3OFrF06dLo2LFjo/Z1RBQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACgKRRFxKuvRvWiRRGvvlp3mQaEKADA5vTGGxE/+EHEXntFq65dY8DZZ0errl0j9tqrbvsbb2RPuNUQogAAm8s990R06xbxla9E/OUvDT/3l7/Ube/WrW4/hCgAwGZxzz0RH/tYxIoVdQ/Dv/eh+DXbVqyo20+Mbj0heskll0SpVIrzzz8/exQAgI3zxhsRn/hEXWjW1q5/39rauv0+8Ymyf5h+qwjRmTNnxoQJE6J3797ZowAAbLz//u+I5cs3HKFr1NbW7f8//9O0c23l0kP0rbfeis985jNx3XXXxXbbbZc9DgDAximKiCuv3LTr/vCHZf1s+lJR5H71Q4cOjU6dOsXll18eRx11VBxwwAFxxRVXrHPflStXxsqVK+svL126NLp37x5VVVVRKpW20MT55tfURNeiiNUR8XL2MDSpUqkU23XqFK///e+R/KtKE7PW5aOc17rrzjtnj9A0Vq+O0sub/l/kt196KaJz5804UK6lS5fG9ttvH0uWLIkOHTqsd9+WW2imdZo8eXLMnj07Zs6c2aj9x48fH+PGjVtr+4033hht2rTZ3ONttdqPGBHxwgtRERHb6K80axRFxGuvRXX2HDQ9a10+ynmt//a37Am2Svf/8pexYscds8fYbJYvX97ofdOOiC5cuDAOOuigmDZtWv25oY6INs5pFRVx5Qc+EG/+7W9l99d0uSnnIyflxlqXj3Jea0dE162cj4hGkWTq1KlFRBQVFRX1HxFRlEqloqKionjnnXc2eBtLliwpIqLsPqqrq4s77rijqK6uTp/Fh7X2Ya19WOvGfmyzamuLYo89iqJUWvMCTY37KJXqrldbm/0VbFZr+mzJkiUb3Dftofl+/frF3LlzG2wbPnx4fOhDH4r/9//+X1RUVCRNBgCwEUqliJEj616sfmN9+ct11y9TaSHavn372HfffRtsa9u2bXTu3Hmt7QAAW7WhQyO+9a26F6tvzEs4tWgRUV0dccYZTT/bViz95ZsAAJq9D3wg4uc/rzu62WIDedWiRd1+t99ed70ylvqs+feaPn169ggAAJtm4MCIX/+67h2T1jxz/N1PSFvzEHx1dV2EDhiw5WfcyjgiCgCwuQwcGPHCCxFXXBGx++4NP7f77nXb//Y3EfoPW9URUQCAZu8DH6h7EtLIkfH2okVx/y9/GUefdFK02nHHsn5i0ro4IgoA0BRKpYjOneterL5zZxG6DkIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFC2zB/hnFEWRPUKKoihi+fLlZfv1lxNrXT6sdfko57VeunRp9ghb3Ntvvx3Lly+PpUuXRqtWrbLH2SLWrHNjfsZLRTP+TXjhhReie/fu2WMAAPAeCxcujG7duq13n2YdorW1tfHiiy9G+/bto1QqZY+zxSxdujS6d+8eCxcujA4dOmSPQxOy1uXDWpcPa11eynG9i6KIN998M7p27RotWqz/LNBm/dB8ixYtNlja27IOHTqUzQ91ubPW5cNalw9rXV7Kbb07duzYqP08WQkAgBRCFACAFEK0GaqsrIwxY8ZEZWVl9ig0MWtdPqx1+bDW5cV6r1+zfrISAADNlyOiAACkEKIAAKQQogAApBCiAACkEKLNzNVXXx09evSIqqqqOPjgg+PRRx/NHokm8MADD8SgQYOia9euUSqV4o477sgeiSYyfvz46NOnT7Rv3z66dOkSgwcPjqeffjp7LJrAtddeG717965/YfO+ffvGXXfdlT0WW8All1wSpVIpzj///OxRtjpCtBmZMmVKjBo1KsaMGROzZ8+O/fffPwYOHBiLFy/OHo3NbNmyZbH//vvH1VdfnT0KTWzGjBlx7rnnxiOPPBLTpk2Lt99+OwYMGBDLli3LHo3NrFu3bnHJJZfErFmz4rHHHotjjjkmPv7xj8e8efOyR6MJzZw5MyZMmBC9e/fOHmWr5OWbmpGDDz44+vTpE1dddVVERNTW1kb37t1j5MiR8Y1vfCN5OppKqVSKqVOnxuDBg7NHYQt45ZVXokuXLjFjxow44ogjssehiXXq1Cm+973vxVlnnZU9Ck3grbfeig9/+MNxzTXXxEUXXRQHHHBAXHHFFdljbVUcEW0mVq1aFbNmzYr+/fvXb2vRokX0798/Hn744cTJgM1pyZIlEVEXKGy7Vq9eHZMnT45ly5ZF3759s8ehiZx77rnxsY99rMF/u2moZfYANM6rr74aq1evjh133LHB9h133DGeeuqppKmAzam2tjbOP//8OPTQQ2PffffNHocmMHfu3Ojbt2/U1NREu3btYurUqdGzZ8/ssWgCkydPjtmzZ8fMmTOzR9mqCVGArcS5554bTz75ZDz44IPZo9BEPvjBD8YTTzwRS5Ysidtuuy2GDh0aM2bMEKPbmIULF8Z5550X06ZNi6qqquxxtmpCtJnYfvvto6KiIhYtWtRg+6JFi2KnnXZKmgrYXEaMGBG/+tWv4oEHHohu3bplj0MTad26dey5554REXHggQfGzJkz4wc/+EFMmDAheTI2p1mzZsXixYvjwx/+cP221atXxwMPPBBXXXVVrFy5MioqKhIn3Ho4R7SZaN26dRx44IFx33331W+rra2N++67z/lF0IwVRREjRoyIqVOnxm9/+9vYbbfdskdiC6qtrY2VK1dmj8Fm1q9fv5g7d2488cQT9R8HHXRQfOYzn4knnnhChL6LI6LNyKhRo2Lo0KFx0EEHxUc+8pG44oorYtmyZTF8+PDs0djM3nrrrZg/f3795QULFsQTTzwRnTp1il122SVxMja3c889NyZNmhS/+MUvon379vHyyy9HRETHjh2juro6eTo2p9GjR8fxxx8fu+yyS7z55psxadKkmD59etxzzz3Zo7GZtW/ffq3zvNu2bRudO3d2/vd7CNFmZMiQIfHKK6/EhRdeGC+//HIccMABcffdd6/1BCaav8ceeyyOPvro+sujRo2KiIihQ4fGxIkTk6aiKVx77bUREXHUUUc12P6Tn/wkhg0btuUHosksXrw4zjjjjHjppZeiY8eO0bt377jnnnvi2GOPzR4N0ngdUQAAUjhHFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFACAFEIUAIAUQhQAgBRCFCDJ6tWr45BDDolTTjmlwfYlS5ZE9+7d41vf+lbSZABbhrf4BEj05z//OQ444IC47rrr4jOf+UxERJxxxhkxZ86cmDlzZrRu3Tp5QoCmI0QBkv3whz+MsWPHxrx58+LRRx+NT37ykzFz5szYf//9s0cDaFJCFCBZURRxzDHHREVFRcydOzdGjhwZ3/72t7PHAmhyQhRgK/DUU0/FPvvsE/vtt1/Mnj07WrZsmT0SQJPzZCWArcCNN94Ybdq0iQULFsQLL7yQPQ7AFuGIKECyhx56KI488si4995746KLLoqIiN/85jdRKpWSJwNoWo6IAiRavnx5DBs2LL70pS/F0UcfHTfccEM8+uij8aMf/Sh7NIAm54goQKLzzjsv7rzzzpgzZ060adMmIiImTJgQF1xwQcydOzd69OiROyBAExKiAElmzJgR/fr1i+nTp8dhhx3W4HMDBw6Md955x0P0wDZNiAIAkMI5ogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACkEKIAAKQQogAApBCiAACk+P9/UoPikz3adQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}